{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "\n",
    "Machine Learning is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions. Instead, these systems learn from data and improve their performance over time. Machine learning can be broadly categorized into three types:\n",
    "\n",
    "1. **Supervised Learning**: The algorithm is trained on labeled data, where the input-output pairs are provided. The goal is to learn a mapping from inputs to outputs.\n",
    "2. **Unsupervised Learning**: The algorithm is trained on unlabeled data and must find patterns and relationships within the data without any specific output labels.\n",
    "3. **Reinforcement Learning**: The algorithm learns by interacting with an environment, receiving feedback in the form of rewards or penalties, and adjusting its actions to maximize cumulative rewards.\n",
    "\n",
    "Machine learning is widely used in various applications, including image and speech recognition, natural language processing, recommendation systems, and autonomous vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![evolution](evolution.jpg)\n",
    "![types](types.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "vb"
    }
   },
   "source": [
    "## Supervised Learning Algorithms\n",
    "\n",
    "### Regression Algorithms\n",
    "1. Linear Regression\n",
    "2. Polynomial Regression\n",
    "3. Ridge Regression\n",
    "4. Lasso Regression\n",
    "5. ElasticNet Regression\n",
    "6. Support Vector Regression (SVR)\n",
    "7. Decision Tree Regression\n",
    "8. Random Forest Regression\n",
    "9. Gradient Boosting Regression\n",
    "10. AdaBoost Regression\n",
    "11. K-Nearest Neighbors Regression (KNN)\n",
    "12. Bayesian Regression\n",
    "\n",
    "### Classification Algorithms\n",
    "1. Logistic Regression\n",
    "2. Support Vector Machines (SVM)\n",
    "3. Decision Tree Classification\n",
    "4. Random Forest Classification\n",
    "5. Gradient Boosting Classification\n",
    "6. AdaBoost Classification\n",
    "7. K-Nearest Neighbors Classification (KNN)\n",
    "8. Naive Bayes Classification\n",
    "9. Linear Discriminant Analysis (LDA)\n",
    "10. Quadratic Discriminant Analysis (QDA)\n",
    "11. Neural Networks (e.g., Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Supervised Learning Algorithms\n",
    "\n",
    "### Regression Algorithms\n",
    "\n",
    "1. **Linear Regression**\n",
    "      - **Description**: Linear Regression is used to predict a continuous target variable based on one or more input features by fitting a linear relationship between the input features and the target variable.\n",
    "      - **Example**: Predicting house prices based on features like square footage, number of bedrooms, and location.\n",
    "\n",
    "2. **Polynomial Regression**\n",
    "      - **Description**: Polynomial Regression is an extension of Linear Regression where the relationship between the input features and the target variable is modeled as an nth degree polynomial.\n",
    "      - **Example**: Predicting the progression of a disease based on time, where the relationship is not linear.\n",
    "\n",
    "3. **Ridge Regression**\n",
    "      - **Description**: Ridge Regression is a type of linear regression that includes a regularization term to prevent overfitting by penalizing large coefficients.\n",
    "      - **Example**: Predicting sales based on advertising spend, with regularization to handle multicollinearity.\n",
    "\n",
    "4. **Lasso Regression**\n",
    "      - **Description**: Lasso Regression is similar to Ridge Regression but uses L1 regularization, which can shrink some coefficients to zero, effectively performing feature selection.\n",
    "      - **Example**: Predicting stock prices with many potential predictors, where Lasso can help identify the most important ones.\n",
    "\n",
    "5. **ElasticNet Regression**\n",
    "      - **Description**: ElasticNet Regression combines both L1 and L2 regularization to balance between Ridge and Lasso regression.\n",
    "      - **Example**: Predicting customer lifetime value with a mix of correlated and uncorrelated features.\n",
    "\n",
    "6. **Support Vector Regression (SVR)**\n",
    "      - **Description**: SVR is a type of Support Vector Machine that is used for regression tasks. It tries to fit the best line within a margin of tolerance.\n",
    "      - **Example**: Predicting the amount of rainfall based on atmospheric data.\n",
    "\n",
    "7. **Decision Tree Regression**\n",
    "      - **Description**: Decision Tree Regression uses a tree-like model of decisions to predict a target variable by learning simple decision rules inferred from the data features.\n",
    "      - **Example**: Predicting the price of a car based on its features like age, mileage, and brand.\n",
    "\n",
    "8. **Random Forest Regression**\n",
    "      - **Description**: Random Forest Regression is an ensemble method that uses multiple decision trees to improve the accuracy and robustness of predictions.\n",
    "      - **Example**: Predicting the yield of a crop based on various environmental factors.\n",
    "\n",
    "9. **Gradient Boosting Regression**\n",
    "      - **Description**: Gradient Boosting Regression builds an ensemble of trees in a sequential manner, where each tree tries to correct the errors of the previous one.\n",
    "      - **Example**: Predicting energy consumption based on historical data and weather conditions.\n",
    "\n",
    "10. **AdaBoost Regression**\n",
    "       - **Description**: AdaBoost Regression is an ensemble method that combines multiple weak learners (usually decision trees) to create a strong learner by focusing on the errors of the previous learners.\n",
    "       - **Example**: Predicting customer churn based on usage patterns and demographics.\n",
    "\n",
    "11. **K-Nearest Neighbors Regression (KNN)**\n",
    "       - **Description**: KNN Regression predicts the target variable by averaging the values of the k-nearest neighbors in the feature space.\n",
    "       - **Example**: Predicting the price of a house based on the prices of nearby houses.\n",
    "\n",
    "12. **Bayesian Regression**\n",
    "       - **Description**: Bayesian Regression incorporates prior knowledge or beliefs into the regression model and updates these beliefs as more data becomes available.\n",
    "       - **Example**: Predicting the success rate of a marketing campaign with prior knowledge of similar past campaigns.\n",
    "\n",
    "### Classification Algorithms\n",
    "\n",
    "1. **Logistic Regression**\n",
    "      - **Description**: Logistic Regression is used for binary classification tasks. It models the probability of a binary outcome using a logistic function.\n",
    "      - **Example**: Predicting whether an email is spam or not based on its content.\n",
    "\n",
    "2. **Support Vector Machines (SVM)**\n",
    "      - **Description**: SVM is a classification algorithm that finds the optimal hyperplane to separate different classes in the feature space.\n",
    "      - **Example**: Classifying images of cats and dogs based on pixel values.\n",
    "\n",
    "3. **Decision Tree Classification**\n",
    "      - **Description**: Decision Tree Classification uses a tree-like model of decisions to classify data by learning simple decision rules inferred from the data features.\n",
    "      - **Example**: Classifying whether a patient has a certain disease based on symptoms and test results.\n",
    "\n",
    "4. **Random Forest Classification**\n",
    "      - **Description**: Random Forest Classification is an ensemble method that uses multiple decision trees to improve the accuracy and robustness of classifications.\n",
    "      - **Example**: Classifying loan applicants as low or high risk based on their financial history.\n",
    "\n",
    "5. **Gradient Boosting Classification**\n",
    "      - **Description**: Gradient Boosting Classification builds an ensemble of trees in a sequential manner, where each tree tries to correct the errors of the previous one.\n",
    "      - **Example**: Classifying customer reviews as positive or negative based on text analysis.\n",
    "\n",
    "6. **AdaBoost Classification**\n",
    "      - **Description**: AdaBoost Classification is an ensemble method that combines multiple weak learners (usually decision trees) to create a strong learner by focusing on the errors of the previous learners.\n",
    "      - **Example**: Classifying images as containing a specific object or not.\n",
    "\n",
    "7. **K-Nearest Neighbors Classification (KNN)**\n",
    "      - **Description**: KNN Classification classifies data points based on the majority class of the k-nearest neighbors in the feature space.\n",
    "      - **Example**: Classifying a new product review as positive or negative based on the reviews of similar products.\n",
    "\n",
    "8. **Naive Bayes Classification**\n",
    "      - **Description**: Naive Bayes Classification is based on Bayes' theorem and assumes that the features are conditionally independent given the class label.\n",
    "      - **Example**: Classifying emails as spam or not spam based on word frequencies.\n",
    "\n",
    "9. **Linear Discriminant Analysis (LDA)**\n",
    "      - **Description**: LDA is a classification method that projects the data onto a lower-dimensional space to maximize the separation between classes.\n",
    "      - **Example**: Classifying handwritten digits based on pixel values.\n",
    "\n",
    "10. **Quadratic Discriminant Analysis (QDA)**\n",
    "       - **Description**: QDA is similar to LDA but allows for different covariance matrices for each class, making it more flexible.\n",
    "       - **Example**: Classifying different types of flowers based on their petal and sepal measurements.\n",
    "\n",
    "11. **Neural Networks (e.g., Multi-Layer Perceptron)**\n",
    "       - **Description**: Neural Networks are a set of algorithms modeled after the human brain that are used to recognize patterns and classify data.\n",
    "       - **Example**: Classifying images of handwritten digits using a multi-layer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\qasim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\qasim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\qasim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\qasim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\qasim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Important Libraries of Machine Learning\n",
    "\n",
    "1. **NumPy**: A fundamental package for numerical computing in Python. It provides support for arrays, matrices, and many mathematical functions.\n",
    "\n",
    "2. **Pandas**: A powerful data manipulation and analysis library. It provides data structures like DataFrame, which is essential for data preprocessing and analysis.\n",
    "\n",
    "3. **Matplotlib**: A plotting library used for creating static, animated, and interactive visualizations in Python.\n",
    "\n",
    "4. **Seaborn**: A statistical data visualization library based on Matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n",
    "5. **Scikit-learn**: A machine learning library that provides simple and efficient tools for data mining and data analysis. It includes various classification, regression, clustering algorithms, and more.\n",
    "\n",
    "6. **TensorFlow**: An open-source library developed by Google for numerical computation and large-scale machine learning. It is widely used for building and training deep learning models.\n",
    "\n",
    "7. **Keras**: A high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It allows for easy and fast prototyping of deep learning models.\n",
    "\n",
    "8. **PyTorch**: An open-source machine learning library developed by Facebook's AI Research lab. It is widely used for deep learning applications and provides a flexible and dynamic computational graph.\n",
    "\n",
    "9. **XGBoost**: An optimized gradient boosting library designed to be highly efficient, flexible, and portable. It is widely used for supervised learning tasks.\n",
    "\n",
    "10. **LightGBM**: A gradient boosting framework that uses tree-based learning algorithms. It is designed to be distributed and efficient, making it suitable for large-scale data.\n",
    "\n",
    "11. **Statsmodels**: A library for estimating and testing statistical models. It provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
